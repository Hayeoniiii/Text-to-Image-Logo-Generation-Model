# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CP-7EPfgn4Zzmnh4j_jaFkOQrre42ZFg
"""

from diffusers import FluxPipeline
from safetensors.torch import load_file
import torch
import os

#Base model 로드
pipe = FluxPipeline.from_pretrained(
    "black-forest-labs/FLUX.1-dev",
    torch_dtype=torch.bfloat16
).to("cuda")

#FluxTransformer2DModel 객체 찾기
def find_flux_model_attr(pipeline):
    for name, module in vars(pipeline).items():
        if module.__class__.__name__ == "FluxTransformer2DModel":
            return name, module
    raise AttributeError("FluxTransformer2DModel 컴포넌트를 찾을 수 없음")

attr_name, flux_model = find_flux_model_attr(pipe)

#LoRA weights 수동 적용
def apply_lora(module, lora_path):
    print(f" LoRA 적용 중: {lora_path}")
    state_dict = load_file(lora_path)
    module.load_state_dict(state_dict, strict=False)
    print(" LoRA 적용 완료")

lora_weights_path = "./downloaded_lora/pytorch_lora_weights.safetensors"
apply_lora(flux_model, lora_weights_path)
setattr(pipe, attr_name, flux_model)

prompt = (
    "'hayeon' logo, white background, simple and minimal style, clean lines "
)

image = pipe(
    prompt=prompt,
    num_inference_steps=50,
    guidance_scale=5.0,    # LoRA 반영 강화
    height=1024,
    width=1024
).images[0]

output_dir = "./outputs"
os.makedirs(output_dir, exist_ok=True)
output_path = os.path.join(output_dir, "simple_and_minimal_logo_lora_local.png")
image.save(output_path)

print(f"생성 완료: {output_path}")